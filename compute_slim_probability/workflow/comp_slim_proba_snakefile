
import os

# This is the snakefile allowing the computation of SLiM likelihood
# by randomization.
# It runs the pipeline using Singularity.

# The following singularity images are used:
# - tagc-mimicint-data-parse.img: A generic environment for input processing and output parsing.
# - tagc-mimicint-slim-detect.img: Required for running the motif detection with SLiMProb.

# Created on: 2020-03-26
# Last update on: 2020-04-29


# Information to the developers regarding multi-processing and file paths:
#   In previous versions, the pipeline was build such as one 'detect_slim_randomized_sqces' job was
#   started for each randomized fasta file generated by the generate_randomized_sequences rule.
#   This was resulting in the run of 2 backgrounds x s strains x n randomizations (for instance  
#   1,400,000 jobs for this single rule if we are considering 100,000 randomizations on 7 strains). 
#   As the clusters we are using are not efficiently handling massive sequential computation but
#   are dealing well with large multi-processing jobs, the pipeline has then been updated in order to
#   lower the number of jobs started for this rule (2 backgrounds x s strains), by grouping the files
#   that needs to be processed with SLiMProb by (background, strain) unique couples.
#
#   Some operations, including this one, requires the script run to get "patterns" of file paths 
#   instead of the actual file paths. Such patterns are replacing the usual "{" and "}" designing 
#   wildcards in the paths respectively by the "[", and "]" characters. All the path corresponding
#   to "patterns" instead of actual file / folder paths are stored in variables having the "_pattern"
#   suffix.

# Load parameters from the configuration file
configfile: "compute_slim_probability/config/config.yaml"


# ===========================================
# Constants
# ===========================================

# Constants
# ---------

MASKED_FASTA_EXTENSION = ".FreqDis.masked.fas"
BACKGROUND_INTRA = "background_intra"
BACKGROUND_INTER = "background_inter"
BACKGROUND_FLAG_CODE_ASSOCIATIONS = { 1: [ BACKGROUND_INTRA ],
                                      2: [ BACKGROUND_INTER ],
                                      3: [ BACKGROUND_INTRA, BACKGROUND_INTER ] }


# Default values for options
# --------------------------

# Default option values for rules
  # ELM parser default options
ELM_PARSER_DEFAULT_OPTIONS = { "pval_threshold_elm_parser": 0.01 }
  
  # Number of shuffled fasta files to generate
DEFAULT_RANDOMIZATION_COUNT = 10000

  # Maximum number of files generated by a single process
DEFAULT_MAX_FILES_GENERATED_PER_PROCESS = 1000

  # Backgrounds to use
DEFAULT_BACKGROUND_FLAG_CODE = 3

  # SLiMProb default options
SLIMPROB_DEFAULT_OPTIONS = { "maxsize": 1000000000, 
                             "maxseq": 10000, 
                             "iumethod": "short",
                             "minregion": 10, 
                             "iucut": 0.2 }

  # SLiM likelihood computations
SLIM_LIKELIHOOD_COMP_OPTIONS = { "get_distributions": False }
  


# Output files and directories
# ----------------------------

# If no output folder is provided in the config file,
# define one by default
if ( "output_folder" not in config.keys() ):
    config[ "output_folder" ] = "output"

# Define output directory and file paths
output_folders = {}
output_files = {}

  # Text file containing all the parameters provided by the user
  # or automatically set by the pipeline
param_file = config.get( "log_parameters_file" )
if param_file:
    output_files[ "log_parameters_file" ] = param_file
else:
    output_files[ "log_parameters_file" ] = os.path.join( "log", "parameters_comp_slim_proba.tsv" )

  # Rule parse_elm
output_folders[ "parse_elm" ] = os.path.join( config[ "output_folder" ], 
                                              "parse_elm" )
output_files[ "elm_motifs_parsed_file" ] = os.path.join( output_folders[ "parse_elm" ], 
                                                         "parsed_elm_classes.txt" )
output_files[ "elm_summary_parsed_file" ] = os.path.join( output_folders[ "parse_elm" ], 
                                                          "parsed_elm_summary.tsv" )
  
  # Rule detect_slim_viral_sqces
config[ "viral_sequence_files" ] = os.path.join( config[ "viral_sequence_folder" ], 
                                                 "{strain}.fasta" )

output_folders[ "slim_detect_viral_sequence" ] = os.path.join( config[ "output_folder" ],
                                                               "slim_detect_viral_sequence" )
output_files[ "viral_sqces_slim_slimprob_list" ] = os.path.join( output_folders[ "slim_detect_viral_sequence" ],
                                                                 "{strain}",
                                                                 "{strain}_slim_slimprob.occ.tsv" )
output_files[ "viral_sqces_slim_slimprob_res" ] = os.path.join( output_folders[ "slim_detect_viral_sequence" ],
                                                                "{strain}",
                                                                "{strain}_slim_slimprob.tsv" )
output_files[ "viral_sqces_slim_slimprob_log_file" ] = os.path.join( output_folders[ "slim_detect_viral_sequence" ],
                                                                     "{strain}",
                                                                     "{strain}_slimprob.log" )
output_folders[ "viral_sqces_slimprob_folder" ] = os.path.join( output_folders[ "slim_detect_viral_sequence" ],
                                                                "{strain}",
                                                                "{strain}_SLiMProb" )
output_files[ "viral_sqces_masked_files" ] = os.path.join( output_folders[ "slim_detect_viral_sequence" ],
                                                           "{strain}",
                                                           "{strain}_SLiMProb",
                                                           "{strain}" + MASKED_FASTA_EXTENSION )

  # Rule copy_masked_fasta_files
output_folders[ "viral_sqces_masked_files_folder" ] = os.path.join( config[ "output_folder" ],
                                                                    "masked_viral_sequence" )
output_files[ "viral_sqces_masked_files_cp" ] = os.path.join( output_folders[ "viral_sqces_masked_files_folder" ],
                                                              "{strain}" + MASKED_FASTA_EXTENSION )


  # Rule generate_randomized_sequences
output_folders[ "randomized_sequence_folder" ] = os.path.join( config[ "output_folder" ], 
                                                               "randomized_sequences" )
output_files[ "randomized_sequence_file" ] = os.path.join( output_folders[ "randomized_sequence_folder" ],
                                                           "{background_flag}", 
                                                           "{strain}", 
                                                           "{strain}_random_{sqce_nb}.fasta" )
output_files[ "randomized_sequence_file_pattern" ] = output_files[ "randomized_sequence_file" ].replace( "{sqce_nb}", "[sqce_nb]" )
output_folders[ "disorder_content_folder" ] = os.path.join( config[ "output_folder" ], 
                                                            "disorder_content" )
output_files[ "randomization_logfile" ] = os.path.join( "log", "randomization.log" )


  # Rule detect_slim_randomized_sqces
output_folders[ "slim_detect_random_sqces" ] = os.path.join( config[ "output_folder" ], 
                                                             "slim_detect_randomized_sequences" )
output_files[ "detect_slim_randomized_sqces_log_file" ] = os.path.join( "log", "detect_slim_randomized_sqces_{background_flag}_{strain}.log" )
output_folders[ "randomized_sqces_slim_slimprob_res_folder" ] = os.path.join( output_folders[ "slim_detect_random_sqces" ],
                                                                              "{background_flag}",
                                                                              "{strain}" )
output_files[ "randomized_sqces_slim_slimprob_res" ] = os.path.join( output_folders[ "randomized_sqces_slim_slimprob_res_folder" ],
                                                                            "{strain}_random_{sqce_nb}_slim_slimprob.tsv" )
output_files[ "randomized_sqces_slim_slimprob_res_pattern" ] = output_files[ "randomized_sqces_slim_slimprob_res" ].replace( "{sqce_nb}", "[sqce_nb]" )
output_files[ "randomized_sqces_slim_slimprob_list" ] = os.path.join( output_folders[ "randomized_sqces_slim_slimprob_res_folder" ],
                                                                      "{strain}_random_{sqce_nb}_slim_slimprob.occ.tsv" )
output_files[ "randomized_sqces_slim_slimprob_list_pattern" ] = output_files[ "randomized_sqces_slim_slimprob_list" ].replace( "{sqce_nb}", "[sqce_nb]" )
output_files[ "randomized_sqces_slim_slimprob_log_file_pattern" ] = os.path.join( output_folders[ "randomized_sqces_slim_slimprob_res_folder" ],
                                                                                 "{strain}_random_[sqce_nb]_slimprob.log" )
output_folders[ "randomized_sqces_slimprob_folder" ] = os.path.join( output_folders[ "randomized_sqces_slim_slimprob_res_folder" ],
																	 "{strain}_SLiMProb" )
output_folders[ "randomized_sqces_slimprob_subfolder_pattern" ] = os.path.join( output_folders[ "randomized_sqces_slimprob_folder" ],
                                                                                "random_[sqce_nb]" )
  
  
  # Rule compute_slim_likelihood
output_files[ "viral_sqces_slim_slimprob_list_pattern" ] = output_files[ "viral_sqces_slim_slimprob_list" ].replace( '{', '[' ).replace( '}', ']' )
output_files[ "randomized_sqces_slim_slimprob_list_full_pattern" ] = output_files[ "randomized_sqces_slim_slimprob_list_pattern" ].replace( '{', '[' ).replace( '}', ']' )

output_folders[ "slim_probabilities_folder" ] =  os.path.join( config[ "output_folder" ],
                                                               "slim_probabilities" )
output_files[ "slim_probabilities" ] = os.path.join( output_folders[ "slim_probabilities_folder" ],
                                                     "{background_flag}.tsv" )
output_files[ "slim_probabilities_pattern" ] = output_files[ "slim_probabilities" ].replace( '{', '[' ).replace( '}', ']' )
  
  
  # Rule plot_motif_distributions
output_files[ "slim_distributions" ] = os.path.join( output_folders[ "slim_probabilities_folder" ], 
                                                     "{background_flag}.html" )


# ===========================================
# Set missing options values
# ===========================================

# Number of random fasta files
if ( "randomization_count" not in config.keys() ):
    config[ "randomization_count" ] = DEFAULT_RANDOMIZATION_COUNT
    
if ( "max_files_generated_per_process" not in config.keys() ):
    config[ "max_files_generated_per_process" ] = DEFAULT_MAX_FILES_GENERATED_PER_PROCESS
    
# Backgrounds
if ( "background_flag_code" ) not in config.keys():
    config["background_flag_code"] = DEFAULT_BACKGROUND_FLAG_CODE
    
config["background_flags"] = BACKGROUND_FLAG_CODE_ASSOCIATIONS[ config[ "background_flag_code" ] ]
        
# List of expected size (1:random_size)
config[ "sqce_nbs" ] = range( config[ "randomization_count" ] )
      
# List of strains
if ( "strains" in config.keys() ):
    config[ "strains" ] = config[ "strains" ].replace(' ,', ',').split(',')
# If the strains have not been defined by the user, 
# determine it from the fasta file names
else:
    fasta_filenames = os.listdir( config[ "viral_sequence_folder" ] )
    config[ "strains" ] = [ filename[ :-len( ".fasta" ) ] for filename in fasta_filenames \
                           if ( filename.endswith( ".fasta" ) ) ]
    config[ "strains_list_string" ] = ','.join( config[ "strains" ] )
        
# ELM parser options
for opt in ELM_PARSER_DEFAULT_OPTIONS.keys():
    if opt not in config.keys():
        config[ opt ] = ELM_PARSER_DEFAULT_OPTIONS[ opt ]
        
# SLiMProb options
for opt in SLIMPROB_DEFAULT_OPTIONS.keys():
    if opt not in config.keys():
        config[ opt ] = SLIMPROB_DEFAULT_OPTIONS[ opt ]
        
# SLiM likelihood computation options
for opt in SLIM_LIKELIHOOD_COMP_OPTIONS.keys():
    if opt not in config.keys():
        config[ opt ] = SLIM_LIKELIHOOD_COMP_OPTIONS[ opt ]
        
# Get the path of the last file expected to be computed by the 
# 'detect_slim_randomized_sqces' rule
# If this file is missing, then this rule will be started
output_files[ "randomized_sqces_slim_slimprob_res_last_file" ] = output_files[ "randomized_sqces_slim_slimprob_res_pattern" ].replace( "[sqce_nb]", str( config[ "sqce_nbs" ][-1] ) )


# ===========================================
# Log the options of the config file
# and parameters automatically set
# ===========================================

basedir = os.path.dirname( output_files[ "log_parameters_file" ] )
if not os.path.isdir( basedir ):
    os.makedirs( basedir )
    
with open( output_files[ "log_parameters_file" ], 'w' ) as parameters_file:
    parameters_file.write( "Parameter" + "\t" + "Value" + "\n" )
    for ( param, value ) in config.items():
        parameters_file.write( param + "\t" + str( value ) + "\n" )



# ===========================================
# Snakemake rules
# ===========================================

# Find which rule is expected to be the last depending if the computation 
# of the SLiM distribution is expected 
if ( config[ "get_distributions" ] ):
    output_files[ "last_rule_output" ] = output_files[ "slim_distributions" ]
else:
    output_files[ "last_rule_output" ] = output_files[ "slim_probabilities" ]


# ---- For dev purpose only ----
# Rule graphs generated using a snakefile with a "all" rule that takes 
# as input all the outputs of the other rules may be useful for workflow
# development as any missing output will be detected and raise a 
# MissingInputException for the "all" rule. Nevertheless, even if the 
# pipeline may be run as is, we strongly discourage to replace the "end" 
# rule by the "all" rule, as a huge number of outputs will be given at
# the same time to the input of the rule "all".
# NB: If the get_distributions option has been selected, then the output of
#     the rule compute_slim_likelihood will not be included as input of the
#     all rule. If you want to add it, then add the following lines to the 
#     inputs of the all rule:
#         slim_probabilities = expand( output_files[ "slim_probabilities" ],
#                                      background_flag = config["background_flags"] ),
# Uncomment following lines to add the all rule.
# rule all:       
#     input:
#         elm_motifs_parsed_file = output_files[ "elm_motifs_parsed_file" ],
#         elm_summary_parsed_file = output_files[ "elm_summary_parsed_file" ],
#         viral_sqces_slim_slimprob_res = expand( output_files[ "viral_sqces_slim_slimprob_res" ],
#                                               strain = config[ "strains" ] ),
#         viral_sqces_slim_slimprob_list = expand( output_files[ "viral_sqces_slim_slimprob_list" ],
#                                               strain = config[ "strains" ] ),
#         viral_sqces_slim_slimprob_log_file = expand( output_files[ "viral_sqces_slim_slimprob_log_file" ],
#                                               strain = config[ "strains" ] ),
#         viral_sqces_masked_files = expand( output_files[ "viral_sqces_masked_files" ],
#                                               strain = config[ "strains" ] ),
#         viral_sqces_masked_files_cp = expand( output_files[ "viral_sqces_masked_files_cp" ],
#                                               strain = config[ "strains" ] ),
#         randomized_sequence_folder = directory( output_folders[ "randomized_sequence_folder" ] ),
#         disorder_content_folder = directory( output_folders[ "disorder_content_folder" ] ),
#         randomization_logfile = output_files[ "randomization_logfile" ],
#         
#         randomized_sqces_slim_slimprob_res_last_file = expand( output_files[ "randomized_sqces_slim_slimprob_res_last_file" ],
#                                                                background_flag = config["background_flags"],
#                                                                strain = config[ "strains" ] ),
#         last_rule_output = expand( output_files[ "last_rule_output" ],
#                                    background_flag = config["background_flags"] )
# ---- For dev purpose only ----
# Snakemake rules
rule end:
    input:
        last_rule_output = expand( output_files[ "last_rule_output" ],
                                   background_flag = config["background_flags"] )



# Parse ELM files
# ---------------

# Parse ELM motif class and instances files to select those linear
# motifs that have been observed in at least one human protein.
# ELM classes are also filtered based on their probability of occurrence
# meaning that "promiscuous" motifs (P>=0.01) are discarded.
rule parse_elm:
    input:
        elm_classes_file = config[ "elm_classes_file" ],
        elm_instances_file = config[ "elm_instances_file" ]
    output:
        elm_motifs_parsed_file = output_files[ "elm_motifs_parsed_file" ],
        elm_summary_parsed_file = output_files[ "elm_summary_parsed_file" ]
    params:
        pval_threshold_elm_parser = config[ "pval_threshold_elm_parser" ]
    singularity : "common/Docker/data_parse/tagc-mimicint-data-parse.img"
    shell:
        "export LC_ALL=C.UTF-8;" 
        "export LANG=C.UTF-8;" 
        "/usr/local/bin/python3 compute_slim_probability/src/fr/tagc/execution/parserELM.py \
         {input.elm_classes_file} {input.elm_instances_file} \
         {output.elm_motifs_parsed_file} {output.elm_summary_parsed_file} \
         {params.pval_threshold_elm_parser}"



# Detect SLiM in viral sequences
# ------------------------------

# Generate the occurrence files and the masked fasta files 
# for the viral ("real") proteins.
rule detect_slim_viral_sqces:
    input:
        elm_motifs_parsed_file = output_files[ "elm_motifs_parsed_file" ],
        viral_sequence_files = config[ 'viral_sequence_files' ]
    output:
        viral_sqces_slim_slimprob_res = output_files[ "viral_sqces_slim_slimprob_res" ],
        viral_sqces_slim_slimprob_list = output_files[ "viral_sqces_slim_slimprob_list" ],
        viral_sqces_slim_slimprob_log_file = output_files[ "viral_sqces_slim_slimprob_log_file" ],
        viral_sqces_masked_files = output_files[ "viral_sqces_masked_files" ]
    params:
        viral_sqces_slimprob_folder = output_folders[ "viral_sqces_slimprob_folder" ],
        maxsize = config[ "maxsize" ],
        maxseq = config[ "maxseq" ],
        minregion = config[ "minregion" ],
        iumethod = config[ "iumethod" ],
        iucut = config[ "iucut" ]
    singularity: "common/Docker/slim_detect/tagc-mimicint-slim-detect.img"
    shell:
        """
        bash compute_slim_probability/script/run_slimprob.sh \
                --motifs {input.elm_motifs_parsed_file} \
                --seqin {input.viral_sequence_files} \
                --resdir {params.viral_sqces_slimprob_folder} \
                --resfile {output.viral_sqces_slim_slimprob_res} \
                --log {output.viral_sqces_slim_slimprob_log_file} \
                --maxsize {params.maxsize} \
                --maxseq {params.maxseq} \
                --minregion {params.minregion} \
                --iumethod {params.iumethod} \
                --iucut {params.iucut}
        """
        
# Copy the masked fasta files in the same folder
rule copy_masked_fasta_files:
    input:
        viral_sqces_masked_files = output_files[ "viral_sqces_masked_files" ]
    output:
        viral_sqces_masked_files_cp = output_files[ "viral_sqces_masked_files_cp" ]
    params:
        viral_sqces_masked_files_folder = output_folders[ "viral_sqces_masked_files_folder" ]
    params:
    shell:
        """
        mkdir -p {params.viral_sqces_masked_files_folder}
        cp {input.viral_sqces_masked_files} {output.viral_sqces_masked_files_cp}
        """
        


# Generate random sequences
# -------------------------

# Generate a set of fasta files by shuffling the sequences
checkpoint generate_randomized_sequences:
    input:
        viral_sqces_masked_files_cp = expand( output_files[ "viral_sqces_masked_files_cp" ],
                                              strain = config[ "strains" ] )
    output:
        randomized_sequence_folder = directory( output_folders[ "randomized_sequence_folder" ] ),
        disorder_content_folder = directory( output_folders[ "disorder_content_folder" ] )
    log:
        randomization_logfile = output_files[ "randomization_logfile" ]
    params:
        viral_sqces_masked_files_folder = output_folders[ "viral_sqces_masked_files_folder" ],
        randomization_count = config[ "randomization_count" ],
        background_flag_code = config[ "background_flag_code" ],
        strains_list_string = config[ "strains_list_string" ],
        max_files_generated_per_process = config[ "max_files_generated_per_process" ]
    threads: 64
    singularity: "common/Docker/data_parse/tagc-mimicint-data-parse.img"
    shell:
        """
        /usr/bin/python2.7 compute_slim_probability/src/fr/tagc/execution/randomize_sequence.py \
         --input {params.viral_sqces_masked_files_folder} \
         --randomSeq {output.randomized_sequence_folder} \
         --disorder {output.disorder_content_folder} \
         --shufflingNumber {params.randomization_count} \
         --backgroundCode {params.background_flag_code} \
         --strain {params.strains_list_string} \
         --threads {threads} \
         --maxFile {params.max_files_generated_per_process} \
         > {log.randomization_logfile}
         """



# Detect SLiMs in random sequences
# --------------------------------

# Define a function related to the generate_randomized_sequences rule,
# so any rule using its output has to wait for it to be finished
def check_generate_randomized_sequences_output( wildcards ):
    # Link the current method to the generate_randomized_sequences rule
    checkpoint_out = checkpoints.generate_randomized_sequences.get()
    
    # Check that all the expected randomized sequences fasta files
    # have been generated and return the last one of the list
    # NB: Using a checkpoint allow to make sure all randomized fasta files 
    #     have been properly generated prior to start any SLiMProb process
    for sqce_nb in config[ "sqce_nbs" ]:
        randomized_fasta_file = output_files[ "randomized_sequence_file" ].format( background_flag = wildcards.background_flag,
                                                                                   strain = wildcards.strain,
                                                                                   sqce_nb = str( sqce_nb ) )
        if not os.path.exists( randomized_fasta_file ):
            raise Exception( 'The file ' + randomized_fasta_file + ' is missing whilst it should' +
                             ' have been generated by the rule "generate_randomized_sequences".' )
            
    
    return randomized_fasta_file
  
    
# Use SLiMProb (SLiM suite) to identify the SLiM in the shuffled sequences
rule detect_slim_randomized_sqces:
    input:
        elm_motifs_parsed_file = output_files[ "elm_motifs_parsed_file" ],
        randomized_sequence_file = check_generate_randomized_sequences_output
    output:
        randomized_sqces_slim_slimprob_res_last_file = output_files[ "randomized_sqces_slim_slimprob_res_last_file" ],
        randomized_sqces_slimprob_folder = temp( directory( output_folders[ "randomized_sqces_slimprob_folder" ] ) )
    log:
        detect_slim_randomized_sqces_log_file = output_files[ "detect_slim_randomized_sqces_log_file" ]
    params:
        randomized_sqces_slim_slimprob_res_folder = output_folders[ "randomized_sqces_slim_slimprob_res_folder" ],
        randomized_sequence_file_pattern = output_files[ "randomized_sequence_file_pattern" ],
        randomized_sqces_slim_slimprob_res_pattern = output_files[ "randomized_sqces_slim_slimprob_res_pattern" ],
        randomized_sqces_slim_slimprob_list_pattern = output_files[ "randomized_sqces_slim_slimprob_list_pattern" ],
        randomized_sqces_slim_slimprob_log_file_pattern = output_files[ "randomized_sqces_slim_slimprob_log_file_pattern" ],
        randomized_sqces_slimprob_subfolder_pattern = output_folders[ "randomized_sqces_slimprob_subfolder_pattern" ],
        randomization_count = config[ "randomization_count" ],
        maxsize = config[ "maxsize" ],
        maxseq = config[ "maxseq" ],
        minregion = config[ "minregion" ],
        iumethod = config[ "iumethod" ],
        iucut = config[ "iucut" ]
    threads: 64
    singularity: "common/Docker/slim_detect/tagc-mimicint-slim-detect.img"
    shell:
        """
        mkdir -p {params.randomized_sqces_slim_slimprob_res_folder}
        mkdir -p {output.randomized_sqces_slimprob_folder}
        /usr/bin/python2.7 compute_slim_probability/script/detect_slim_randomized_sqces.py \
                --motifs {input.elm_motifs_parsed_file} \
                --seqinPattern {params.randomized_sequence_file_pattern} \
                --resdirPattern {params.randomized_sqces_slimprob_subfolder_pattern} \
                --resfilePattern {params.randomized_sqces_slim_slimprob_res_pattern} \
                --logPattern {params.randomized_sqces_slim_slimprob_log_file_pattern} \
                --shufflingNumber {params.randomization_count} \
                --threads {threads} \
                --maxsize {params.maxsize} \
                --maxseq {params.maxseq} \
                --minregion {params.minregion} \
                --iumethod {params.iumethod} \
                --iucut {params.iucut} \
            > {log.detect_slim_randomized_sqces_log_file}
        """



# Compute the SLiM likelihoods
# ----------------------------

# Parse the SLiM result files and compute the probability of occurrence 
# of each SLiM on each sequence
rule compute_slim_likelihood:
    input:
        viral_sqces_slim_slimprob_list = expand( output_files[ "viral_sqces_slim_slimprob_list" ],
                                                 strain = config[ "strains" ] ),
        randomized_sqces_slim_slimprob_res_first_file = expand( output_files[ "randomized_sqces_slim_slimprob_res_last_file" ],
                                                                background_flag = config["background_flags"],
                                                                strain = config[ "strains" ] )
    output:
        slim_probabilities = output_files[ "slim_probabilities" ]
    params:
        viral_sqces_slim_slimprob_list_pattern = output_files[ "viral_sqces_slim_slimprob_list_pattern" ],
        randomized_sqces_slim_slimprob_list_full_pattern = output_files[ "randomized_sqces_slim_slimprob_list_full_pattern" ],
        slim_probabilities_pattern = output_files[ "slim_probabilities_pattern" ],
        background_flag = '{background_flag}',
        strains_list_string = config[ "strains_list_string" ],
        randomization_count = config[ "randomization_count" ],
        get_distributions = config[ "get_distributions" ]
    threads: 64
    singularity: "common/Docker/data_parse/tagc-mimicint-data-parse.img"
    shell:
        """
        /usr/local/bin/python3 compute_slim_probability/src/fr/tagc/execution/compute_slim_likelihood.py \
        -v {params.viral_sqces_slim_slimprob_list_pattern} \
        -r {params.randomized_sqces_slim_slimprob_list_full_pattern} \
        -o {params.slim_probabilities_pattern} \
        -b {params.background_flag} \
        -s {params.strains_list_string} \
        -n {params.randomization_count} \
        --threads {threads} \
        -d {params.get_distributions}
        """



# Plot the SLiM distributions
# ---------------------------
# Parse the SLiM result files and compute the probability of occurrence 
# of each SLiM on each sequence
rule plot_motif_distributions:
    input:
        slim_probabilities = output_files[ "slim_probabilities" ]
    output:
        slim_distributions = output_files[ "slim_distributions" ]
    singularity: "common/Docker/Rstudio/tagc-mimicint-rstudio.img"
    shell:
        """
        export LC_ALL=C.UTF-8 
        export LANG=C.UTF-8
        export R_LIBS_USER=/usr/local/lib/R/site-library
        /R-3.6.0/bin/Rscript compute_slim_probability/script/compile_plot_distributions.R \
        -i {input.slim_probabilities} \
        -o {output.slim_distributions}
        """
        