#!/usr/bin/python3
# -*- coding: utf-8 -*-

import os
from optparse import OptionParser
import pandas as pd

from multiprocessing import Pool


# This script allows to parse the files containing the SLiM occurrences
# for the viral ("real") sequences as well as the files containing the
# SLiM occurrences for the randomized sequences. Using information from
# these files, it then compute the likelihood of each motif for each 
# sequence of each strain.

# NB: In order to work properly, this script expects the appropriate number
#     of randomized sequences files to have been generated properly and the
#     occurrence files to have been computed using SLiMProb. For more information
#     about these steps, please refer to the scripts and source code files.


# ===========================================
# Constants
# ===========================================

# Background flags
BACKGROUND_FLAG_INTRA = 'background_intra'
BACKGROUND_FLAG_INTER = 'background_inter'
DEFAULT_BACKGROUND_FLAGS = [ BACKGROUND_FLAG_INTRA, BACKGROUND_FLAG_INTER ]

# Default number of shuffling to perform
DEFAULT_RANDOM_ITERATIONS = 10000


# List of options allowed
# -----------------------

# "Schema" of the path to the "natural" ("real") occurrences files
SLIM_NAT_OCC_PROT_OPTION = 'SLIM_NAT_OCC_PROT'
# "Schema" of the path to the randomized occurrences files
SLIM_RANDOM_OCC_SQCES_OPTION = 'SLIM_RANDOM_OCC_SQCES'
# "Schema" of the path to the output file, containing the SLiM likelihood
SLIM_LIKELIHOOD_OUTPUT_OPTION = 'SLIM_LIKELIHOOD_OUTPUT'
# List of background flags to use
BACKGROUND_FLAGS_OPTION = 'BACKGROUND_FLAGS'
# List of strain names
STRAIN_NAMES_OPTION = 'STRAIN_NAMES'
# Number of randomizations
RANDOM_ITERATIONS_OPT = 'ITERATIONS_OPT'
# Number of threads available
THREAD_NB_COUNT_OPTION = 'THREAD_NB_COUNT'
# Distribution option
GET_DISTRIBUTIONS_OPTION = 'GET_DISTRIBUTIONS'

OPTION_LIST = [ [ '-v', '--viralOcc', 'store', 'string', SLIM_NAT_OCC_PROT_OPTION, None, 'The "schema" of the path to the "natural" ("real") occurrences files. \
                                                                                          It must be a string containing "{strain}".' ],
                [ '-r', '--ramdomOcc', 'store', 'string', SLIM_RANDOM_OCC_SQCES_OPTION, None, 'The "schema" of the path to the randomized occurrences files. \
                                                                                               It must be a string containing "{background_flag}", "{strain}" and "{sqce_nb}".' ],
                [ '-o', '--output', 'store', 'string', SLIM_LIKELIHOOD_OUTPUT_OPTION, None, 'The "schema" of the path to the output file, containing the SLiM likelihoods.\
                                                                                             It must be a string containing {background_flag}' ],
                [ '-b', '--background', 'store', 'string', BACKGROUND_FLAGS_OPTION, None, 'The comma-separated list of background files (background_inter and background_intra by default).' ],
                [ '-s', '--strain', 'store', 'string', STRAIN_NAMES_OPTION, None, 'The comma-separated list of strains.' ],
                [ '-n', '--shufflingNumber', 'store', 'string', RANDOM_ITERATIONS_OPT, None, 'The number of randomization performed.' ],
                [ '-t', '--threads', 'store', 'string', THREAD_NB_COUNT_OPTION, None, 'The number of threads allocated to the SLiMProb processes.' ],
                [ '-d', '--getDistributions', 'store', 'string', GET_DISTRIBUTIONS_OPTION, None, 'For each unique (motif, sequence) couple, get the number of occurrences for each shuffled sequence.' ] ]
    


# ===========================================
# Methods
# ===========================================

# parse_occ_files
# ---------------
#
# This method allows to parse the occurrence files generated by SLiMProb 
# for each viral ("real") sequence and all the occurrence files generated 
# for each of the randomized sequences and to compute the likelihood of 
# each SLiM existing in the viral sequences.
#
# @param slim_occ_viral_prot_filepath: String - The "schema" of the path to the 
#                                               viral ("real") occurrences files. 
#                                               NB: Must contain {strain}
# @param slim_occ_random_sqces_filepath: String - The "schema" of the path to the 
#                                                 randomized occurrences files.
#                                                 NB: Must contain {background_flag}, {strain} and {sqce_nb}
# @param occ_fqce_filepath: String - The "schema" of the path to the output file, 
#                                    that will contain the SLiM likelihood.
#                                    NB: Must contain {background_flag}.
# @param background_flags: List - The list of background flags.
# @param strains: List - The list of strains.
# @param random_iterations: Integer - The number of iterations performed
# @param get_distributions: Boolean - Should the occurrence of motifs in shuffled 
#                                     sequences be reported? False by default.
#
def parse_occ_files( slim_occ_viral_prot_filepath, slim_occ_random_sqces_filepath, occ_fqce_filepath, \
                     background_flags, strains, random_iterations, thread_nb, get_distributions=False ):
    
    # Instantiate a dictionary that associate to each unique (motif, strain, sequence) 
    # tuple, the number of occurrence in the "real" viral sequence.
    # i.e., Keys are (motif, strain, sequence) - 3-Tuple
    #       Values are Occurence count in viral sequence - Integer
    slim_occ_all_viral_prot = {}
    
    # For each protein of each strain, get the number of occurrence 
    # of each SLiM in its viral ("real") sequence.
    for strain in strains:
        
        # For each unique (motif, sequence) couple, 
        # get the number of occurrence of the SLiM
        slim_occ_viral_prot = get_occ_count( ( slim_occ_viral_prot_filepath.format( strain = strain ),
                                               strain ) )
        
        # Update the dictionary that register every (motif, strain, sequence) 
        # couple existing
        if isinstance( slim_occ_viral_prot, dict ):
            slim_occ_all_viral_prot.update( slim_occ_viral_prot )
        else:
            raise slim_occ_viral_prot
        
        
    # For each protein of each strain, compute the frequency at which a SLiM
    # is observed by chance (i.e. in randomized sequences) at least the same
    # number of time than in the viral ("real") sequence; for each type of
    # randomization (i.e. intra and inter species background).    
    for background_flag in background_flags:
            
        # Instantiate a dictionary that associate to each unique (motif, strain, sequence) 
        # tuple, the number of occurrence in the "real" viral sequence and the total count
        # of randomized sequences that harbor the SLiM at least the same number of occurrence
        # as observed for sequences generated with the current background.
        # NB: Keys are (motif, strain, sequence) - 3-Tuple
        #     Values are [ Occ. count in viral sequence (Integer), 
        #                  Number of shuffled sequences for which the motif occurrence is higher
        #                      than in the viral sequence (Integer),
        #                  Number of occurrences of the motif for each shuffled 
        #                      sequence (List of integers) ] - List
        slim_occ_viral_prot_bckg = { key: [ val, 0, [] ] for ( key, val ) in slim_occ_all_viral_prot.items() }
        
        
        # For each protein of each strain, get the number of time each SLiM
        # has been observed at least as many time than in the viral ("real") 
        # sequence for each SLiM. 
        
        for strain in strains:
        
            # First, instantiate the list of arguments to multi-process the count
            # of time each motif has been detected on each sequence
            get_occ_count_args = []
            
            # Get the number of occurrences for each randomized sequences file
            for iteration in range( random_iterations ):
                get_occ_count_args.append( ( slim_occ_random_sqces_filepath.format( background_flag = background_flag,
                                                                                    strain = strain,
                                                                                    sqce_nb = iteration ),
                                             strain ) )
                
            # Instantiate the pool
            p = Pool( thread_nb )
            slim_occ_random_sqce = p.map( get_occ_count, get_occ_count_args )
            p.close()
            
            # Wait for all processes to be completed
            p.join()
            
            # Check no exception has been raised by one of the process
            for occ_count in slim_occ_random_sqce:
                if isinstance( occ_count, Exception ):
                    raise occ_count
            
            
            # Add the information to the dictionary
            for occ_count in slim_occ_random_sqce:
                for ( key, val ) in slim_occ_viral_prot_bckg.items():
                    if ( key[ 1 ] == strain ):
                        # If this couple (motif, strain, sequence) has been reported
                        # in the occurrence file, then add the number of occurrences to 
                        # the list. This will be used to compute the empirical p-value
                        # and to provide the distributions if asked.
                        occ_random_count = occ_count.get( key )
                            
                        if ( occ_random_count ):
                            slim_occ_viral_prot_bckg[ key ][ 2 ].append( occ_random_count )
                        else:
                            slim_occ_viral_prot_bckg[ key ][ 2 ].append( 0 )
        
        
        # For each motif on each sequence registered in the dictionary,
        # compute the number of times the motifs has been found at least
        # the same number of time in the random sequences that in the 
        # corresponding "real" sequence
        for ( key, val ) in slim_occ_viral_prot_bckg.items():
            occ_count_higher_than_viral_sqce = map( lambda x: x >= val[ 0 ], 
                                                    val[ 2 ] )
            slim_occ_viral_prot_bckg[ key ][ 1 ] = sum( occ_count_higher_than_viral_sqce )
                                
        # Compute the frequency of occurrence assuming a random distribution
        basedir = os.path.dirname( occ_fqce_filepath.format( background_flag = background_flag ) )
        if not os.path.isdir(basedir):
            os.makedirs(basedir)
            
        with open( occ_fqce_filepath.format( background_flag = background_flag ), 'w' ) as output_file:
            
            # Add header to the file
            header = [ 'motif', 'strain', 'sequence', 'viral_prot_count', 'rdm_occ', 'rdm_freq', 'empirical_pval' ]
            if ( get_distributions ):
                header.append( 'rdm_occ_counts' )
                
            output_file.write( '\t'.join( header ) + '\n' )
            
            for ( key, val ) in slim_occ_viral_prot_bckg.items():
                
                motif = key[ 0 ]
                strain = key[ 1 ]
                sequence = key[ 2 ]
                
                # Get the "natural" number of occurrences
                nat_occ = val[ 0 ]
                
                # Get the number of time the motif occurrences were more numerous 
                # than in the viral sequence
                rdm_occ = val[ 1 ]
                # Compute the frequency according to the total number of iterations
                rdm_freq = float( rdm_occ ) / float( random_iterations )
                # Compute the empirical p-value
                emp_pval = float( rdm_occ + 1 ) / float( random_iterations + 1 )
                
                # Get the distribution of occurrences for this (motif, sequence) couple
                if ( get_distributions ):
                    rdm_occ_distrib = ','.join( list( map( str, val[ 2 ] ) ) )
                else:
                    rdm_occ_distrib = ''
                
                # Write the line in the output file
                output_file.write( '\t'.join( list( map( str, [ motif, strain, sequence, nat_occ, 
                                                                rdm_occ, rdm_freq, emp_pval, 
                                                                rdm_occ_distrib ] ) ) ) + '\n'  )
                
                

# get_occ_count
# -------------
#
# This method allows to open an occurrence file generated 
# by SLiMProb (.occ.tsv file) and to return a dictionary 
# that associate to each unique tuple (motif, strain, sequence)
# the number of time the motif has been encountered in the 
# sequence.
#
# @param occ_args: 2-tuple - A 2-element tuple containing:
#                            - occ_file: String - Path to the occurrence file.
#                            - strain: String - Name of the strain expected to be contained
#                                               in the occurrence file.
#
# @return occ_dict: Dictionary - A dictionary that associate to each 
#                                unique tuple (motif, strain, sequence)
#                                encountered in the file the number of 
#                                time the motif has been encountered in 
#                                the sequence.
#
# @return Exception - When the dataset contained in the file is not the 
#                     one expected.
# @return Exception - When there are several datasets contained in the same 
#                     file.
#
def get_occ_count( occ_args ):
    
    # Parse the arguments
    ( occ_file, strain ) = occ_args
        
    # Import the content of the file as a pandas data frame
    file_content = pd.read_csv( occ_file,
                                sep = '\t',
                                dtype = 'str',
                                encoding = 'utf-8' )
    
    # Make sure there is one single dataset contained in 
    # this occurrence file
    datasets = list( set( file_content[ 'Dataset' ] ) )
    if ( len( datasets ) == 1 ):
        dataset = datasets[ 0 ]
        # Check the dataset contained in the occurence file
        # correspond to the expected strain
        if ( not dataset.startswith( strain ) ):
            return Exception( 'The occurrence file contains information about ' + 
                              dataset + ' whilst it is expected to contain information about ' +
                              strain + '.' )
    
        # Extract the columns containing the names 
        # of the motifs and the sequences
        file_content = file_content[ [ 'Motif', 'Seq' ] ]
        
        # For each unique (motif, sequence) couple, 
        # get the number of occurrence of the SLiM
        file_content = file_content.groupby( [ 'Motif', 'Seq' ] ).size().reset_index()
        file_content = file_content.rename( columns = { 0: 'Count' } )
        
        # Convert the Pandas data frame into a dictionary
        occ_dict = {}
        for ( index, row ) in file_content.iterrows():
            occ_dict[ ( row[ 'Motif' ], strain, row[ 'Seq' ] ) ] = row[ 'Count' ]
            
    else:
        if ( len( datasets ) == 0 ):
            print( 'The occurrence file ' + occ_file + ' do not contain any dataset.' )
            occ_dict = {}
            
        else:
            return Exception( 'The occurrence file ' + occ_file + ' contains information from several datasets (' + 
                              ', '.join( datasets ) + ') whilst it is expected to only contain' +
                              ' information about ' + strain + '.' )
        
    return occ_dict



# ===========================================
# Parse options and run script
# ===========================================

if __name__ == '__main__':
    
    ## Command-line arguments are parsed.
    # Store the various option values into a dictionary
    optionParser = OptionParser()    
    for current_opt in OPTION_LIST:
        optionParser.add_option( current_opt[0],
                                 current_opt[1],
                                 action = current_opt[2],
                                 type = current_opt[3],
                                 dest = current_opt[4],
                                 default = current_opt[5],
                                 help = current_opt[6] )
    (opts, args) = optionParser.parse_args()
    option_dict = vars(opts)
    
    # Get the "schema" of the path to the "natural" ("real") occurrences files
    slim_occ_viral_prot_filepath = option_dict.get( SLIM_NAT_OCC_PROT_OPTION )
    if slim_occ_viral_prot_filepath:
        slim_occ_viral_prot_filepath = slim_occ_viral_prot_filepath.replace( '[', '{' ).replace( ']', '}' )
        if ( '{strain}' not in slim_occ_viral_prot_filepath ):
            raise Exception( 'The "schema" of the path to the viral ("real") occurrences files' +
                             ' has to contain "{strain}".' )
    else:
        raise Exception( 'The "schema" of the path to the viral ("real") occurrences files' +
                         ' has to be provided.' )
    
    # Get the "schema" of the path to the randomized occurrences files
    slim_occ_random_sqces_filepath = option_dict.get( SLIM_RANDOM_OCC_SQCES_OPTION )
    if slim_occ_random_sqces_filepath:
        slim_occ_random_sqces_filepath = slim_occ_random_sqces_filepath.replace( '[', '{' ).replace( ']', '}' )
        if ( ( '{background_flag}' not in slim_occ_random_sqces_filepath )
             or ( '{strain}' not in slim_occ_random_sqces_filepath )
             or ( '{sqce_nb}' not in slim_occ_random_sqces_filepath ) ):
            raise Exception( 'The "schema" of the path to the randomized occurrences files' +
                             ' has to contain "{background_flag}", "{strain}" and "{sqce_nb}".' )
    else:
        raise Exception( 'The "schema" of the path to the randomized occurrences files' +
                         ' has to be provided.' )
    
    # Get the "schema" of the path to the output file, containing the SLiM likelihood
    occ_fqce_filepath = option_dict.get( SLIM_LIKELIHOOD_OUTPUT_OPTION )
    if occ_fqce_filepath:
        occ_fqce_filepath = occ_fqce_filepath.replace( '[', '{' ).replace( ']', '}' )
        if ( '{background_flag}' not in occ_fqce_filepath ):
            raise Exception( 'The "schema" of the path to the output file has to contain "{background_flag}".' )
    else:
        raise Exception( 'The "schema" of the path to the output file has to be provided.' )
    
    # Get the background flags 
    background_flags = option_dict.get( BACKGROUND_FLAGS_OPTION, DEFAULT_BACKGROUND_FLAGS )
    if background_flags:
        background_flags = background_flags.replace( ', ', ',' ).split( ',' )
        if isinstance( background_flags, str ):
            background_flags = [ background_flags ]
    
    # Get the strain names 
    strains = option_dict.get( STRAIN_NAMES_OPTION )
    if strains:
        strains = strains.split( ',' )
    else:
        raise Exception( 'The list of strains to use has to be provided.' )
    
    # Get the number of iterations to perform
    random_iterations = option_dict.get( RANDOM_ITERATIONS_OPT, DEFAULT_RANDOM_ITERATIONS )
    if random_iterations:
        random_iterations = int( random_iterations )
        if ( random_iterations < 1 ):
            raise Exception( 'The number of iterations (' + str( random_iterations ) + 
                             ') to perform has to be a positive integer.' )

    # Get the number of threads
    thread_nb = option_dict.get( THREAD_NB_COUNT_OPTION )
    if thread_nb:
        try:
            thread_nb = int( thread_nb )
        except:
            raise Exception( 'The number of threads has to be an integer.' )
        else:
            if ( thread_nb <= 0 ):
                raise Exception( 'The number of threads has to be a positive integer.' )
    else:
        thread_nb = 1
    
    # Get the distribution option
    # If selected, the list of number of occurrence in each 
    # shuffled sequence will be reported for each motif
    get_distributions = option_dict.get( GET_DISTRIBUTIONS_OPTION, False )
    try:
        get_distributions = eval( get_distributions )
    except:
        raise Exception( 'The get_distributions option (' + str( get_distributions ) + 
                         ') has to be a boolean.' )
    else:
        if ( get_distributions not in [ True, False, None ] ): 
            raise Exception( 'The get_distributions option (' + str( get_distributions ) + 
                             ') has to be a boolean.' )
    
    # Compute the SLiM likelihoods
    print( 'INFO :: Starting to compute the SLiM probabilities.' )
    parse_occ_files( slim_occ_viral_prot_filepath = slim_occ_viral_prot_filepath, 
                     slim_occ_random_sqces_filepath = slim_occ_random_sqces_filepath,  
                     occ_fqce_filepath = occ_fqce_filepath,
                     background_flags = background_flags,
                     strains = strains, 
                     random_iterations = random_iterations,
                     thread_nb = thread_nb,
                     get_distributions = get_distributions )
    print( 'INFO :: The SLiM probabilities have been computed.' )

    